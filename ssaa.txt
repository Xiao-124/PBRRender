/////////////////////////////// Source file 0/////////////////////////////
#version 410 core

#extension GL_ARB_shading_language_packing : enable

#extension GL_GOOGLE_cpp_style_line_directive : enable

/////////////////////////////// Source file 1/////////////////////////////
#define SPIRV_CROSS_CONSTANT_ID_0 3
#define SPIRV_CROSS_CONSTANT_ID_1 64
#define SPIRV_CROSS_CONSTANT_ID_4 2048
#define SPIRV_CROSS_CONSTANT_ID_6 false
#define SPIRV_CROSS_CONSTANT_ID_7 false
#define SPIRV_CROSS_CONSTANT_ID_2 false
#define SPIRV_CROSS_CONSTANT_ID_5 false
#define SPIRV_CROSS_CONSTANT_ID_8 2


/////////////////////////////// Source file 2/////////////////////////////

/////////////////////////////// Source file 3/////////////////////////////

#define TARGET_GL_ENVIRONMENT
#define FILAMENT_OPENGL_SEMANTICS
#define FILAMENT_HAS_FEATURE_TEXTURE_GATHER
#define FILAMENT_HAS_FEATURE_INSTANCING
#define FILAMENT_EFFECTIVE_VERSION __VERSION__
#define VARYING in
#define SHADING_MODEL_UNLIT
#define FILAMENT_QUALITY_LOW    0
#define FILAMENT_QUALITY_NORMAL 1
#define FILAMENT_QUALITY_HIGH   2
#define FILAMENT_QUALITY FILAMENT_QUALITY_HIGH

precision highp float;
precision highp int;

#ifndef SPIRV_CROSS_CONSTANT_ID_0
#define SPIRV_CROSS_CONSTANT_ID_0 1
#endif
const int BACKEND_FEATURE_LEVEL = SPIRV_CROSS_CONSTANT_ID_0;

#ifndef SPIRV_CROSS_CONSTANT_ID_1
#define SPIRV_CROSS_CONSTANT_ID_1 64
#endif
const int CONFIG_MAX_INSTANCES = SPIRV_CROSS_CONSTANT_ID_1;

#ifndef SPIRV_CROSS_CONSTANT_ID_4
#define SPIRV_CROSS_CONSTANT_ID_4 1024
#endif
const int CONFIG_FROXEL_BUFFER_HEIGHT = SPIRV_CROSS_CONSTANT_ID_4;

#ifndef SPIRV_CROSS_CONSTANT_ID_6
#define SPIRV_CROSS_CONSTANT_ID_6 false
#endif
const bool CONFIG_DEBUG_DIRECTIONAL_SHADOWMAP = SPIRV_CROSS_CONSTANT_ID_6;

#ifndef SPIRV_CROSS_CONSTANT_ID_7
#define SPIRV_CROSS_CONSTANT_ID_7 false
#endif
const bool CONFIG_DEBUG_FROXEL_VISUALIZATION = SPIRV_CROSS_CONSTANT_ID_7;

#ifndef SPIRV_CROSS_CONSTANT_ID_2
#define SPIRV_CROSS_CONSTANT_ID_2 false
#endif
const bool CONFIG_STATIC_TEXTURE_TARGET_WORKAROUND = SPIRV_CROSS_CONSTANT_ID_2;

#ifndef SPIRV_CROSS_CONSTANT_ID_5
#define SPIRV_CROSS_CONSTANT_ID_5 false
#endif
const bool CONFIG_POWER_VR_SHADER_WORKAROUNDS = SPIRV_CROSS_CONSTANT_ID_5;

#ifndef SPIRV_CROSS_CONSTANT_ID_8
#define SPIRV_CROSS_CONSTANT_ID_8 2
#endif
const int CONFIG_STEREO_EYE_COUNT = SPIRV_CROSS_CONSTANT_ID_8;

#define CONFIG_MAX_STEREOSCOPIC_EYES 4

#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 0                      
#endif
#if defined(FILAMENT_VULKAN_SEMANTICS)
#define LAYOUT_LOCATION(x) layout(location = x)
#else
#define LAYOUT_LOCATION(x)
#endif

#define bool2    bvec2
#define bool3    bvec3
#define bool4    bvec4

#define int2     ivec2
#define int3     ivec3
#define int4     ivec4

#define uint2    uvec2
#define uint3    uvec3
#define uint4    uvec4

#define float2   vec2
#define float3   vec3
#define float4   vec4

#define float3x3 mat3
#define float4x4 mat4

// To workaround an adreno crash (#5294), we need ensure that a method with
// parameter 'const mat4' does not call another method also with a 'const mat4'
// parameter (i.e. mulMat4x4Float3). So we remove the const modifier for
// materials compiled for vulkan+mobile.
#if defined(TARGET_VULKAN_ENVIRONMENT) && defined(TARGET_MOBILE)
   #define highp_mat4 highp mat4
#else
   #define highp_mat4 const highp mat4
#endif

#define POST_PROCESS_OPAQUE 1

LAYOUT_LOCATION(0) VARYING highp vec4 variable_vertex;

layout(std140) uniform FrameUniforms {
    mat4 viewFromWorldMatrix;
    mat4 worldFromViewMatrix;
    mat4 clipFromViewMatrix;
    mat4 viewFromClipMatrix;
    mat4 clipFromWorldMatrix[4];
    mat4 worldFromClipMatrix;
    mat4 userWorldFromWorldMatrix;
    vec4 clipTransform;
    vec2 clipControl;
    float time;
    float temporalNoise;
    vec4 userTime;
    vec4 resolution;
    vec2 logicalViewportScale;
    vec2 logicalViewportOffset;
    float lodBias;
    float refractionLodOffset;
    lowp vec2 derivativesScale;
    float oneOverFarMinusNear;
    float nearOverFarMinusNear;
    float cameraFar;
    float exposure;
    float ev100;
    float needsAlphaChannel;
    lowp float aoSamplingQualityAndEdgeDistance;
    lowp float aoBentNormals;
    lowp vec4 zParams;
    lowp uvec3 fParams;
    lowp int lightChannels;
    lowp vec2 froxelCountXY;
    float iblLuminance;
    float iblRoughnessOneLevel;
    lowp vec3 iblSH[9];
    vec3 lightDirection;
    lowp float padding0;
    vec4 lightColorIntensity;
    vec4 sun;
    vec2 shadowFarAttenuationParams;
    lowp int directionalShadows;
    lowp float ssContactShadowDistance;
    vec4 cascadeSplits;
    lowp int cascades;
    lowp float shadowPenumbraRatioScale;
    vec2 lightFarAttenuationParams;
    lowp float vsmExponent;
    lowp float vsmDepthScale;
    lowp float vsmLightBleedReduction;
    lowp uint shadowSamplingType;
    vec3 fogDensity;
    float fogStart;
    float fogMaxOpacity;
    uint fogMinMaxMip;
    float fogHeightFalloff;
    float fogCutOffDistance;
    vec3 fogColor;
    float fogColorFromIbl;
    float fogInscatteringStart;
    float fogInscatteringSize;
    float fogOneOverFarMinusNear;
    float fogNearOverFarMinusNear;
    mat3 fogFromWorldMatrix;
    mat4 ssrReprojection;
    mat4 ssrUvFromViewMatrix;
    lowp float ssrThickness;
    lowp float ssrBias;
    lowp float ssrDistance;
    lowp float ssrStride;
    vec4 custom[4];
    int rec709;
    lowp float es2Reserved0;
    lowp float es2Reserved1;
    lowp float es2Reserved2;
    lowp vec4 reserved[40];
} frameUniforms;

layout(std140) uniform MaterialParams {
    mat4 screenFromViewMatrix;
    vec4 resolution;
    vec2 positionParams;
    float invRadiusSquared;
    float minHorizonAngleSineSquared;
    float peak2;
    float projectionScale;
    float projectionScaleRadius;
    float bias;
    float power;
    float intensity;
    float spiralTurns;
    vec2 sampleCount;
    vec2 angleIncCosSin;
    float invFarPlane;
    int maxLevel;
    vec2 reserved;
    float ssctShadowDistance;
    float ssctConeAngleTangeant;
    float ssctContactDistanceMaxInv;
    vec3 ssctVsLightDirection;
    float ssctIntensity;
    vec2 ssctDepthBias;
    vec2 ssctRayCount;
    uint ssctSampleCount;
} materialParams;
uniform highp sampler2D materialParams_depth;

#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 0                   
#endif
//------------------------------------------------------------------------------
// Common math
//------------------------------------------------------------------------------

/** @public-api */
#define PI                 3.14159265359
/** @public-api */
#define HALF_PI            1.570796327

#define MEDIUMP_FLT_MAX    65504.0
#define MEDIUMP_FLT_MIN    0.00006103515625

#ifdef TARGET_MOBILE
#define FLT_EPS            MEDIUMP_FLT_MIN
#define saturateMediump(x) min(x, MEDIUMP_FLT_MAX)
#else
#define FLT_EPS            1e-5
#define saturateMediump(x) x
#endif

#define saturate(x)        clamp(x, 0.0, 1.0)

//------------------------------------------------------------------------------
// Scalar operations
//------------------------------------------------------------------------------

/**
 * Computes x^5 using only multiply operations.
 *
 * @public-api
 */
float pow5(float x) {
    float x2 = x * x;
    return x2 * x2 * x;
}

/**
 * Computes x^2 as a single multiplication.
 *
 * @public-api
 */
float sq(float x) {
    return x * x;
}

//------------------------------------------------------------------------------
// Vector operations
//------------------------------------------------------------------------------

/**
 * Returns the maximum component of the specified vector.
 *
 * @public-api
 */
float max3(const vec3 v) {
    return max(v.x, max(v.y, v.z));
}

float vmax(const vec2 v) {
    return max(v.x, v.y);
}

float vmax(const vec3 v) {
    return max(v.x, max(v.y, v.z));
}

float vmax(const vec4 v) {
    return max(max(v.x, v.y), max(v.y, v.z));
}

/**
 * Returns the minimum component of the specified vector.
 *
 * @public-api
 */
float min3(const vec3 v) {
    return min(v.x, min(v.y, v.z));
}

float vmin(const vec2 v) {
    return min(v.x, v.y);
}

float vmin(const vec3 v) {
    return min(v.x, min(v.y, v.z));
}

float vmin(const vec4 v) {
    return min(min(v.x, v.y), min(v.y, v.z));
}

//------------------------------------------------------------------------------
// Trigonometry
//------------------------------------------------------------------------------

/**
 * Approximates acos(x) with a max absolute error of 9.0x10^-3.
 * Valid in the range -1..1.
 */
float acosFast(float x) {
    // Lagarde 2014, "Inverse trigonometric functions GPU optimization for AMD GCN architecture"
    // This is the approximation of degree 1, with a max absolute error of 9.0x10^-3
    float y = abs(x);
    float p = -0.1565827 * y + 1.570796;
    p *= sqrt(1.0 - y);
    return x >= 0.0 ? p : PI - p;
}

/**
 * Approximates acos(x) with a max absolute error of 9.0x10^-3.
 * Valid only in the range 0..1.
 */
float acosFastPositive(float x) {
    float p = -0.1565827 * x + 1.570796;
    return p * sqrt(1.0 - x);
}

//------------------------------------------------------------------------------
// Matrix and quaternion operations
//------------------------------------------------------------------------------

/**
 * Multiplies the specified 3-component vector by the 4x4 matrix (m * v) in
 * high precision.
 *
 * @public-api
 */
highp vec4 mulMat4x4Float3(const highp mat4 m, const highp vec3 v) {
    return v.x * m[0] + (v.y * m[1] + (v.z * m[2] + m[3]));
}

/**
 * Multiplies the specified 3-component vector by the 3x3 matrix (m * v) in
 * high precision.
 *
 * @public-api
 */
highp vec3 mulMat3x3Float3(const highp mat4 m, const highp vec3 v) {
    return v.x * m[0].xyz + (v.y * m[1].xyz + (v.z * m[2].xyz));
}

/**
 * Extracts the normal vector of the tangent frame encoded in the specified quaternion.
 */
void toTangentFrame(const highp vec4 q, out highp vec3 n) {
    n = vec3( 0.0,  0.0,  1.0) +
        vec3( 2.0, -2.0, -2.0) * q.x * q.zwx +
        vec3( 2.0,  2.0, -2.0) * q.y * q.wzy;
}

/**
 * Extracts the normal and tangent vectors of the tangent frame encoded in the
 * specified quaternion.
 */
void toTangentFrame(const highp vec4 q, out highp vec3 n, out highp vec3 t) {
    toTangentFrame(q, n);
    t = vec3( 1.0,  0.0,  0.0) +
        vec3(-2.0,  2.0, -2.0) * q.y * q.yxw +
        vec3(-2.0,  2.0,  2.0) * q.z * q.zwx;
}

highp mat3 cofactor(const highp mat3 m) {
    highp float a = m[0][0];
    highp float b = m[1][0];
    highp float c = m[2][0];
    highp float d = m[0][1];
    highp float e = m[1][1];
    highp float f = m[2][1];
    highp float g = m[0][2];
    highp float h = m[1][2];
    highp float i = m[2][2];

    highp mat3 cof;
    cof[0][0] = e * i - f * h;
    cof[0][1] = c * h - b * i;
    cof[0][2] = b * f - c * e;
    cof[1][0] = f * g - d * i;
    cof[1][1] = a * i - c * g;
    cof[1][2] = c * d - a * f;
    cof[2][0] = d * h - e * g;
    cof[2][1] = b * g - a * h;
    cof[2][2] = a * e - b * d;
    return cof;
}

//------------------------------------------------------------------------------
// Random
//------------------------------------------------------------------------------

/*
 * Random number between 0 and 1, using interleaved gradient noise.
 * w must not be normalized (e.g. window coordinates)
 */
float interleavedGradientNoise(highp vec2 w) {
    const vec3 m = vec3(0.06711056, 0.00583715, 52.9829189);
    return fract(m.z * fract(dot(w, m.xy)));
}
#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 0                    
#endif
// These variables should be in a struct but some GPU drivers ignore the
// precision qualifier on individual struct members
highp mat3  shading_tangentToWorld;   // TBN matrix
highp vec3  shading_position;         // position of the fragment in world space
      vec3  shading_view;             // normalized vector from the fragment to the eye
      vec3  shading_normal;           // normalized transformed normal, in world space
      vec3  shading_geometricNormal;  // normalized geometric normal, in world space
      vec3  shading_reflected;        // reflection of view about normal
      float shading_NoV;              // dot(normal, view), always strictly >= MIN_N_DOT_V

#if defined(MATERIAL_HAS_BENT_NORMAL)
      vec3  shading_bentNormal;       // normalized transformed normal, in world space
#endif

#if defined(MATERIAL_HAS_CLEAR_COAT)
      vec3  shading_clearCoatNormal;  // normalized clear coat layer normal, in world space
#endif

highp vec2 shading_normalizedViewportCoord;
#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 0                     
#endif
//------------------------------------------------------------------------------
// Common color operations
//------------------------------------------------------------------------------

/**
 * Computes the luminance of the specified linear RGB color using the
 * luminance coefficients from Rec. 709.
 *
 * @public-api
 */
float luminance(const vec3 linear) {
    return dot(linear, vec3(0.2126, 0.7152, 0.0722));
}

/**
 * Computes the pre-exposed intensity using the specified intensity and exposure.
 * This function exists to force highp precision on the two parameters
 */
float computePreExposedIntensity(const highp float intensity, const highp float exposure) {
    return intensity * exposure;
}

void unpremultiply(inout vec4 color) {
    color.rgb /= max(color.a, FLT_EPS);
}

/**
 * Applies a full range YCbCr to sRGB conversion and returns an RGB color.
 *
 * @public-api
 */
vec3 ycbcrToRgb(float luminance, vec2 cbcr) {
    // Taken from https://developer.apple.com/documentation/arkit/arframe/2867984-capturedimage
    const mat4 ycbcrToRgbTransform = mat4(
         1.0000,  1.0000,  1.0000,  0.0000,
         0.0000, -0.3441,  1.7720,  0.0000,
         1.4020, -0.7141,  0.0000,  0.0000,
        -0.7010,  0.5291, -0.8860,  1.0000
    );
    return (ycbcrToRgbTransform * vec4(luminance, cbcr, 1.0)).rgb;
}

//------------------------------------------------------------------------------
// Tone mapping operations
//------------------------------------------------------------------------------

/*
 * The input must be in the [0, 1] range.
 */
vec3 Inverse_Tonemap_Filmic(const vec3 x) {
    return (0.03 - 0.59 * x - sqrt(0.0009 + 1.3702 * x - 1.0127 * x * x)) / (-5.02 + 4.86 * x);
}

/**
 * Applies the inverse of the tone mapping operator to the specified HDR or LDR
 * sRGB (non-linear) color and returns a linear sRGB color. The inverse tone mapping
 * operator may be an approximation of the real inverse operation.
 *
 * @public-api
 */
vec3 inverseTonemapSRGB(vec3 color) {
    // sRGB input
    color = clamp(color, 0.0, 1.0);
    return Inverse_Tonemap_Filmic(pow(color, vec3(2.2)));
}

/**
 * Applies the inverse of the tone mapping operator to the specified HDR or LDR
 * linear RGB color and returns a linear RGB color. The inverse tone mapping operator
 * may be an approximation of the real inverse operation.
 *
 * @public-api
 */
vec3 inverseTonemap(vec3 linear) {
    // Linear input
    return Inverse_Tonemap_Filmic(clamp(linear, 0.0, 1.0));
}

//------------------------------------------------------------------------------
// Common texture operations
//------------------------------------------------------------------------------

/**
 * Decodes the specified RGBM value to linear HDR RGB.
 */
vec3 decodeRGBM(vec4 c) {
    c.rgb *= (c.a * 16.0);
    return c.rgb * c.rgb;
}

//------------------------------------------------------------------------------
// Common screen-space operations
//------------------------------------------------------------------------------

// returns the frag coord in the GL convention with (0, 0) at the bottom-left
// resolution : width, height
highp vec2 getFragCoord(const highp vec2 resolution) {
#if defined(TARGET_METAL_ENVIRONMENT) || defined(TARGET_VULKAN_ENVIRONMENT)
    return vec2(gl_FragCoord.x, resolution.y - gl_FragCoord.y);
#else
    return gl_FragCoord.xy;
#endif
}

//------------------------------------------------------------------------------
// Common debug
//------------------------------------------------------------------------------

vec3 heatmap(float v) {
    vec3 r = v * 2.1 - vec3(1.8, 1.14, 0.3);
    return 1.0 - r * r;
}
#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 0                      
#endif
//------------------------------------------------------------------------------
// Uniforms access
//------------------------------------------------------------------------------

/** @public-api */
highp mat4 getViewFromWorldMatrix() {
    return frameUniforms.viewFromWorldMatrix;
}

/** @public-api */
highp mat4 getWorldFromViewMatrix() {
    return frameUniforms.worldFromViewMatrix;
}

/** @public-api */
highp mat4 getClipFromViewMatrix() {
    return frameUniforms.clipFromViewMatrix;
}

/** @public-api */
highp mat4 getViewFromClipMatrix() {
    return frameUniforms.viewFromClipMatrix;
}

/** @public-api */
highp mat4 getClipFromWorldMatrix() {
#if defined(VARIANT_HAS_INSTANCED_STEREO)
    int eye = instance_index % CONFIG_STEREO_EYE_COUNT;
    return frameUniforms.clipFromWorldMatrix[eye];
#else
    return frameUniforms.clipFromWorldMatrix[0];
#endif
}

/** @public-api */
highp mat4 getWorldFromClipMatrix() {
    return frameUniforms.worldFromClipMatrix;
}

/** @public-api */
highp mat4 getUserWorldFromWorldMatrix() {
    return frameUniforms.userWorldFromWorldMatrix;
}

/** @public-api */
float getTime() {
    return frameUniforms.time;
}

/** @public-api */
highp vec4 getUserTime() {
    return frameUniforms.userTime;
}

/** @public-api **/
highp float getUserTimeMod(float m) {
    return mod(mod(frameUniforms.userTime.x, m) + mod(frameUniforms.userTime.y, m), m);
}

/**
 * Transforms a texture UV to make it suitable for a render target attachment.
 *
 * In Vulkan and Metal, texture coords are Y-down but in OpenGL they are Y-up. This wrapper function
 * accounts for these differences. When sampling from non-render targets (i.e. uploaded textures)
 * these differences do not matter because OpenGL has a second piece of backwardness, which is that
 * the first row of texels in glTexImage2D is interpreted as the bottom row.
 *
 * To protect users from these differences, we recommend that materials in the SURFACE domain
 * leverage this wrapper function when sampling from offscreen render targets.
 *
 * @public-api
 */
highp vec2 uvToRenderTargetUV(const highp vec2 uv) {
#if defined(TARGET_METAL_ENVIRONMENT) || defined(TARGET_VULKAN_ENVIRONMENT)
    return vec2(uv.x, 1.0 - uv.y);
#else
    return uv;
#endif
}

// TODO: below shouldn't be accessible from post-process materials

/** @public-api */
highp vec4 getResolution() {
    return frameUniforms.resolution;
}

/** @public-api */
highp vec3 getWorldCameraPosition() {
    return frameUniforms.worldFromViewMatrix[3].xyz;
}

/** @public-api, @deprecated use getUserWorldPosition() or getUserWorldFromWorldMatrix() instead  */
highp vec3 getWorldOffset() {
    return getUserWorldFromWorldMatrix()[3].xyz;
}

/** @public-api */
float getExposure() {
    // NOTE: this is a highp uniform only to work around #3602 (qualcomm)
    // We are intentionally casting it to mediump here, as per the Materials doc.
    return frameUniforms.exposure;
}

/** @public-api */
float getEV100() {
    return frameUniforms.ev100;
}

//------------------------------------------------------------------------------
// user defined globals
//------------------------------------------------------------------------------

highp vec4 getMaterialGlobal0() {
    return frameUniforms.custom[0];
}

highp vec4 getMaterialGlobal1() {
    return frameUniforms.custom[1];
}

highp vec4 getMaterialGlobal2() {
    return frameUniforms.custom[2];
}

highp vec4 getMaterialGlobal3() {
    return frameUniforms.custom[3];
}

#define FRAG_OUTPUT0 color
#define FRAG_OUTPUT_AT0 output_color
#define FRAG_OUTPUT_MATERIAL_TYPE0 vec4
#define FRAG_OUTPUT_PRECISION0 
#define FRAG_OUTPUT_TYPE0 vec4
#define FRAG_OUTPUT_SWIZZLE0 

layout(location=0) out  vec4 output_color;
#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 0                         
#endif

struct PostProcessInputs {
#if defined(FRAG_OUTPUT0)
    FRAG_OUTPUT_PRECISION0 FRAG_OUTPUT_MATERIAL_TYPE0 FRAG_OUTPUT0;
#endif
#if defined(FRAG_OUTPUT1)
    FRAG_OUTPUT_PRECISION1 FRAG_OUTPUT_MATERIAL_TYPE1 FRAG_OUTPUT1;
#endif
#if defined(FRAG_OUTPUT2)
    FRAG_OUTPUT_PRECISION2 FRAG_OUTPUT_MATERIAL_TYPE2 FRAG_OUTPUT2;
#endif
#if defined(FRAG_OUTPUT3)
    FRAG_OUTPUT_PRECISION3 FRAG_OUTPUT_MATERIAL_TYPE3 FRAG_OUTPUT3;
#endif
#if defined(FRAG_OUTPUT4)
    FRAG_OUTPUT_PRECISION4 FRAG_OUTPUT_MATERIAL_TYPE4 FRAG_OUTPUT4;
#endif
#if defined(FRAG_OUTPUT5)
    FRAG_OUTPUT_PRECISION5 FRAG_OUTPUT_MATERIAL_TYPE5 FRAG_OUTPUT5;
#endif
#if defined(FRAG_OUTPUT6)
    FRAG_OUTPUT_PRECISION6 FRAG_OUTPUT_MATERIAL_TYPE6 FRAG_OUTPUT6;
#endif
#if defined(FRAG_OUTPUT7)
    FRAG_OUTPUT_PRECISION7 FRAG_OUTPUT_MATERIAL_TYPE7 FRAG_OUTPUT7;
#endif
#if defined(FRAG_OUTPUT_DEPTH)
    float depth;
#endif
};
#line 128
#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 127          
#endif


#define COMPUTE_BENT_NORMAL 0

    #if defined(GL_GOOGLE_cpp_style_line_directive)
#line 0             
#endif
/*
 * Copyright (C) 2021 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/*
 * This is our implementation of SAO -- it's not standalone because it uses materialParams
 * directly. Therefore it must be included in *.mat file that has all these parameters.
 * The main reason for using a separate file is to be able to have several version of the
 * code with only minor changes.
 */

#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 0               
#endif
/*
 * Copyright (C) 2021 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef FILAMENT_MATERIALS_SSAO_UTILS
#define FILAMENT_MATERIALS_SSAO_UTILS

#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 0                         
#endif
/*
 * Copyright (C) 2021 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef FILAMENT_MATERIALS_DEPTH_UTILS
#define FILAMENT_MATERIALS_DEPTH_UTILS

highp float linearizeDepth(highp float depth) {
    // Our far plane is at infinity, which causes a division by zero below, which in turn
    // causes some issues on some GPU. We workaround it by replacing "infinity" by the closest
    // value representable in  a 24 bit depth buffer.
    const highp float preventDiv0 = 1.0 / 16777216.0;
    mat4 p = getViewFromClipMatrix();
    // this works with perspective and ortho projections, for a perspective projection
    // this resolves to -near/depth, for an ortho projection this resolves to depth*(far - near) - far
    return (depth * p[2].z + p[3].z) / max(depth * p[2].w + p[3].w, preventDiv0);
}

highp float sampleDepth(const highp sampler2D depthTexture, const highp vec2 uv, float lod) {
    return textureLod(depthTexture, uvToRenderTargetUV(uv), lod).r;
}

highp float sampleDepthLinear(const highp sampler2D depthTexture,
        const highp vec2 uv, float lod) {
    return linearizeDepth(sampleDepth(depthTexture, uv, lod));
}

#endif // #define FILAMENT_MATERIALS_DEPTH_UTILS


#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 19               
#endif


vec2 pack(highp float normalizedDepth) {
    // we need 16-bits of precision
    highp float z = clamp(normalizedDepth, 0.0, 1.0);
    highp float t = floor(256.0 * z);
    mediump float hi = t * (1.0 / 256.0);   // we only need 8-bits of precision
    mediump float lo = (256.0 * z) - t;     // we only need 8-bits of precision
    return vec2(hi, lo);
}

highp float unpack(highp vec2 depth) {
    // depth here only has 8-bits of precision, but the unpacked depth is highp
    // this is equivalent to (x8 * 256 + y8) / 65535, which gives a value between 0 and 1
    return (depth.x * (256.0 / 257.0) + depth.y * (1.0 / 257.0));
}

vec3 packBentNormal(vec3 bn) {
    return bn * 0.5 + 0.5;
}

vec3 unpackBentNormal(vec3 bn) {
    return bn * 2.0 - 1.0;
}


#endif // FILAMENT_MATERIALS_SSAO_UTILS


#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 23             
#endif

#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 0                       
#endif
/*
 * Copyright (C) 2021 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef FILAMENT_MATERIALS_GEOMETRY
#define FILAMENT_MATERIALS_GEOMETRY

#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 0                
#endif
/*
 * Copyright (C) 2021 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef FILAMENT_MATERIALS_DEPTH_UTILS
#define FILAMENT_MATERIALS_DEPTH_UTILS

highp float linearizeDepth(highp float depth) {
    // Our far plane is at infinity, which causes a division by zero below, which in turn
    // causes some issues on some GPU. We workaround it by replacing "infinity" by the closest
    // value representable in  a 24 bit depth buffer.
    const highp float preventDiv0 = 1.0 / 16777216.0;
    mat4 p = getViewFromClipMatrix();
    // this works with perspective and ortho projections, for a perspective projection
    // this resolves to -near/depth, for an ortho projection this resolves to depth*(far - near) - far
    return (depth * p[2].z + p[3].z) / max(depth * p[2].w + p[3].w, preventDiv0);
}

highp float sampleDepth(const highp sampler2D depthTexture, const highp vec2 uv, float lod) {
    return textureLod(depthTexture, uvToRenderTargetUV(uv), lod).r;
}

highp float sampleDepthLinear(const highp sampler2D depthTexture,
        const highp vec2 uv, float lod) {
    return linearizeDepth(sampleDepth(depthTexture, uv, lod));
}

#endif // #define FILAMENT_MATERIALS_DEPTH_UTILS


#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 19                       
#endif


// uv             : normalized coordinates
// linearDepth    : linear depth at uv
// positionParams : invProjection[0][0] * 2, invProjection[1][1] * 2
//
highp vec3 computeViewSpacePositionFromDepth(highp vec2 uv, highp float linearDepth,
        highp vec2 positionParams) {
    return vec3((0.5 - uv) * positionParams * linearDepth, linearDepth);
}

highp vec3 faceNormal(highp vec3 dpdx, highp vec3 dpdy) {
    return normalize(cross(dpdx, dpdy));
}

// Compute normals using derivatives, which essentially results in half-resolution normals
// this creates arifacts around geometry edges.
// Note: when using the spirv optimizer, this results in much slower execution time because
//       this whole expression is inlined in the AO loop below.
highp vec3 computeViewSpaceNormalLowQ(const highp vec3 position) {
    return faceNormal(dFdx(position), dFdy(position));
}

// Compute normals directly from the depth texture, resulting in full resolution normals
// Note: This is actually as cheap as using derivatives because the texture fetches
//       are essentially equivalent to textureGather (which we don't have on ES3.0),
//       and this is executed just once.
//
// depthTexture   : the depth texture in reversed-Z
// uv             : normalized coordinates
// position       : view space position at uv
// texel          : 1/depth_width, 1/depth_height
// positionParams : invProjection[0][0] * 2, invProjection[1][1] * 2
//
highp vec3 computeViewSpaceNormalMediumQ(
        const highp sampler2D depthTexture, const highp vec2 uv,
        const highp vec3 position,
        highp vec2 texel, highp vec2 positionParams) {

    precision highp float;

    highp vec2 uvdx = uv + vec2(texel.x, 0.0);
    highp vec2 uvdy = uv + vec2(0.0, texel.y);
    vec3 px = computeViewSpacePositionFromDepth(uvdx,
            sampleDepthLinear(depthTexture, uvdx, 0.0), positionParams);
    vec3 py = computeViewSpacePositionFromDepth(uvdy,
            sampleDepthLinear(depthTexture, uvdy, 0.0), positionParams);
    vec3 dpdx = px - position;
    vec3 dpdy = py - position;
    return faceNormal(dpdx, dpdy);
}

// Accurate view-space normal reconstruction
// Based on Yuwen Wu "Accurate Normal Reconstruction"
// (https://atyuwen.github.io/posts/normal-reconstruction)
//
// depthTexture   : the depth texture in reversed-Z
// uv             : normalized coordinates
// depth          : linear depth at uv
// position       : view space position at uv
// texel          : 1/depth_width, 1/depth_height
// positionParams : invProjection[0][0] * 2, invProjection[1][1] * 2
//
highp vec3 computeViewSpaceNormalHighQ(
        const highp sampler2D depthTexture, const highp vec2 uv,
        const highp float depth, const highp vec3 position,
        highp vec2 texel, highp vec2 positionParams) {

    precision highp float;

    vec3 pos_c = position;
    highp vec2 dx = vec2(texel.x, 0.0);
    highp vec2 dy = vec2(0.0, texel.y);

    vec4 H;
    H.x = sampleDepth(depthTexture, uv - dx, 0.0);
    H.y = sampleDepth(depthTexture, uv + dx, 0.0);
    H.z = sampleDepth(depthTexture, uv - dx * 2.0, 0.0);
    H.w = sampleDepth(depthTexture, uv + dx * 2.0, 0.0);
    vec2 he = abs((2.0 * H.xy - H.zw) - depth);
    vec3 pos_l = computeViewSpacePositionFromDepth(uv - dx,
            linearizeDepth(H.x), positionParams);
    vec3 pos_r = computeViewSpacePositionFromDepth(uv + dx,
            linearizeDepth(H.y), positionParams);
    vec3 dpdx = (he.x < he.y) ? (pos_c - pos_l) : (pos_r - pos_c);

    vec4 V;
    V.x = sampleDepth(depthTexture, uv - dy, 0.0);
    V.y = sampleDepth(depthTexture, uv + dy, 0.0);
    V.z = sampleDepth(depthTexture, uv - dy * 2.0, 0.0);
    V.w = sampleDepth(depthTexture, uv + dy * 2.0, 0.0);
    vec2 ve = abs((2.0 * V.xy - V.zw) - depth);
    vec3 pos_d = computeViewSpacePositionFromDepth(uv - dy,
            linearizeDepth(V.x), positionParams);
    vec3 pos_u = computeViewSpacePositionFromDepth(uv + dy,
            linearizeDepth(V.y), positionParams);
    vec3 dpdy = (ve.x < ve.y) ? (pos_c - pos_d) : (pos_u - pos_c);
    return faceNormal(dpdx, dpdy);
}

// depthTexture   : the depth texture in reversed-Z
// uv             : normalized coordinates
// depth          : linear depth at uv
// position       : view space position at uv
// texel          : 1/depth_width, 1/depth_height
// positionParams : invProjection[0][0] * 2, invProjection[1][1] * 2
//
highp vec3 computeViewSpaceNormal(
        const highp sampler2D depthTexture, const highp vec2 uv,
        const highp float depth, const highp vec3 position,
        highp vec2 texel, highp vec2 positionParams) {
    // todo: maybe make this a quality parameter
#if FILAMENT_QUALITY == FILAMENT_QUALITY_HIGH
    vec3 normal = computeViewSpaceNormalHighQ(depthTexture, uv, depth, position,
            texel, positionParams);
#else
    vec3 normal = computeViewSpaceNormalMediumQ(depthTexture, uv, position,
            texel, positionParams);
#endif
    return normal;
}

#endif // FILAMENT_MATERIALS_GEOMETRY

#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 24             
#endif


#ifndef COMPUTE_BENT_NORMAL
#error COMPUTE_BENT_NORMAL must be set
#endif

const float kLog2LodRate = 3.0;

// Ambient Occlusion, largely inspired from:
// "The Alchemy Screen-Space Ambient Obscurance Algorithm" by Morgan McGuire
// "Scalable Ambient Obscurance" by Morgan McGuire, Michael Mara and David Luebke

vec3 tapLocation(float i, const float noise) {
    float offset = ((2.0 * PI) * 2.4) * noise;
    float angle = ((i * materialParams.sampleCount.y) * materialParams.spiralTurns) * (2.0 * PI) + offset;
    float radius = (i + noise + 0.5) * materialParams.sampleCount.y;
    return vec3(cos(angle), sin(angle), radius * radius);
}

highp vec2 startPosition(const float noise) {
    float angle = ((2.0 * PI) * 2.4) * noise;
    return vec2(cos(angle), sin(angle));
}

highp mat2 tapAngleStep() {
    highp vec2 t = materialParams.angleIncCosSin;
    return mat2(t.x, t.y, -t.y, t.x);
}

vec3 tapLocationFast(float i, vec2 p, const float noise) {
    float radius = (i + noise + 0.5) * materialParams.sampleCount.y;
    return vec3(p, radius * radius);
}

void computeAmbientOcclusionSAO(inout float occlusion, inout vec3 bentNormal,
        float i, float ssDiskRadius,
        const highp vec2 uv,  const highp vec3 origin, const vec3 normal,
        const vec2 tapPosition, const float noise) {

    vec3 tap = tapLocationFast(i, tapPosition, noise);

    float ssRadius = max(1.0, tap.z * ssDiskRadius); // at least 1 pixel screen-space radius

    vec2 uvSamplePos = uv + vec2(ssRadius * tap.xy) * materialParams.resolution.zw;

    float level = clamp(floor(log2(ssRadius)) - kLog2LodRate, 0.0, float(materialParams.maxLevel));
    highp float occlusionDepth = sampleDepthLinear(materialParams_depth, uvSamplePos, level);
    highp vec3 p = computeViewSpacePositionFromDepth(uvSamplePos, occlusionDepth, materialParams.positionParams);

    // now we have the sample, compute AO
    highp vec3 v = p - origin;  // sample vector
    float vv = dot(v, v);       // squared distance
    float vn = dot(v, normal);  // distance * cos(v, normal)

    // discard samples that are outside of the radius, preventing distant geometry to
    // cast shadows -- there are many functions that work and choosing one is an artistic
    // decision.
    float w = sq(max(0.0, 1.0 - vv * materialParams.invRadiusSquared));

    // discard samples that are too close to the horizon to reduce shadows cast by geometry
    // not sufficently tessellated. The goal is to discard samples that form an angle 'beta'
    // smaller than 'epsilon' with the horizon. We already have dot(v,n) which is equal to the
    // sin(beta) * |v|. So the test simplifies to vn^2 < vv * sin(epsilon)^2.
    w *= step(vv * materialParams.minHorizonAngleSineSquared, vn * vn);

    float sampleOcclusion = max(0.0, vn + (origin.z * materialParams.bias)) / (vv + materialParams.peak2);
    occlusion += w * sampleOcclusion;

#if COMPUTE_BENT_NORMAL

    // TODO: revisit how we choose to keep the normal or not
    // reject samples beyond the far plane
    if (occlusionDepth * materialParams.invFarPlane < 1.0) {
        float rr = 1.0 / materialParams.invRadiusSquared;
        float cc = vv - vn*vn;
        float s = sqrt(max(0.0, rr - cc));
        vec3 n = normalize(v + normal * (s - vn));// vn is negative
        bentNormal += n * (sampleOcclusion <= 0.0 ? 1.0 : 0.0);
    }

#endif
}

void scalableAmbientObscurance(out float obscurance, out vec3 bentNormal,
        highp vec2 uv, highp vec3 origin, vec3 normal) {
    float noise = interleavedGradientNoise(getFragCoord(materialParams.resolution.xy));
    highp vec2 tapPosition = startPosition(noise);
    highp mat2 angleStep = tapAngleStep();

    // Choose the screen-space sample radius
    // proportional to the projected area of the sphere
    float ssDiskRadius = -(materialParams.projectionScaleRadius / origin.z);

    obscurance = 0.0;
    bentNormal = normal;
    for (float i = 0.0; i < materialParams.sampleCount.x; i += 1.0) {
        computeAmbientOcclusionSAO(obscurance, bentNormal,
                i, ssDiskRadius, uv, origin, normal, tapPosition, noise);
        tapPosition = angleStep * tapPosition;
    }
    obscurance = sqrt(obscurance * materialParams.intensity);
#if COMPUTE_BENT_NORMAL
    bentNormal = normalize(bentNormal);
#endif
}

#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 131          
#endif

    #if defined(GL_GOOGLE_cpp_style_line_directive)
#line 0              
#endif
/*
 * Copyright (C) 2021 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 0          
#endif
/*
 * Copyright (C) 2021 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef FILAMENT_MATERIALS_SSCT
#define FILAMENT_MATERIALS_SSCT

/*
 * Largely based on "Dominant Light Shadowing"
 * "Lighting Technology of The Last of Us Part II" by Hawar Doghramachi, Naughty Dog, LLC
 */

#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 0               
#endif
/*
 * Copyright (C) 2021 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef FILAMENT_MATERIALS_SSAO_UTILS
#define FILAMENT_MATERIALS_SSAO_UTILS

#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 0                         
#endif
/*
 * Copyright (C) 2021 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef FILAMENT_MATERIALS_DEPTH_UTILS
#define FILAMENT_MATERIALS_DEPTH_UTILS

highp float linearizeDepth(highp float depth) {
    // Our far plane is at infinity, which causes a division by zero below, which in turn
    // causes some issues on some GPU. We workaround it by replacing "infinity" by the closest
    // value representable in  a 24 bit depth buffer.
    const highp float preventDiv0 = 1.0 / 16777216.0;
    mat4 p = getViewFromClipMatrix();
    // this works with perspective and ortho projections, for a perspective projection
    // this resolves to -near/depth, for an ortho projection this resolves to depth*(far - near) - far
    return (depth * p[2].z + p[3].z) / max(depth * p[2].w + p[3].w, preventDiv0);
}

highp float sampleDepth(const highp sampler2D depthTexture, const highp vec2 uv, float lod) {
    return textureLod(depthTexture, uvToRenderTargetUV(uv), lod).r;
}

highp float sampleDepthLinear(const highp sampler2D depthTexture,
        const highp vec2 uv, float lod) {
    return linearizeDepth(sampleDepth(depthTexture, uv, lod));
}

#endif // #define FILAMENT_MATERIALS_DEPTH_UTILS


#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 19               
#endif


vec2 pack(highp float normalizedDepth) {
    // we need 16-bits of precision
    highp float z = clamp(normalizedDepth, 0.0, 1.0);
    highp float t = floor(256.0 * z);
    mediump float hi = t * (1.0 / 256.0);   // we only need 8-bits of precision
    mediump float lo = (256.0 * z) - t;     // we only need 8-bits of precision
    return vec2(hi, lo);
}

highp float unpack(highp vec2 depth) {
    // depth here only has 8-bits of precision, but the unpacked depth is highp
    // this is equivalent to (x8 * 256 + y8) / 65535, which gives a value between 0 and 1
    return (depth.x * (256.0 / 257.0) + depth.y * (1.0 / 257.0));
}

vec3 packBentNormal(vec3 bn) {
    return bn * 0.5 + 0.5;
}

vec3 unpackBentNormal(vec3 bn) {
    return bn * 2.0 - 1.0;
}


#endif // FILAMENT_MATERIALS_SSAO_UTILS


#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 24          
#endif


const float kSSCTLog2LodRate = 3.0;

struct ConeTraceSetup {
    // fragment info
    highp vec2 ssStartPos;
    highp vec3 vsStartPos;
    vec3 vsNormal;

    // light (cone) info
    vec3 vsConeDirection;
    float shadowDistance;
    float coneAngleTangeant;
    float contactDistanceMaxInv;
    vec2 jitterOffset;          // (x = direction offset, y = step offset)

    // scene infos
    highp mat4 screenFromViewMatrix;
    float projectionScale;
    vec4 resolution;
    float maxLevel;

    // artistic/quality parameters
    float intensity;
    float depthBias;
    float slopeScaledDepthBias;
    uint sampleCount;
};

highp float getWFromProjectionMatrix(const highp mat4 p, const vec3 v) {
    // this essentially returns (p * vec4(v, 1.0)).w, but we make some assumptions
    // this assumes a perspective projection
    return -v.z;
    // this assumes a perspective or ortho projection
    //return p[2][3] * v.z + p[3][3];
}

highp float getViewSpaceZFromW(const highp mat4 p, const float w) {
    // this assumes a perspective projection
    return -w;
    // this assumes a perspective or ortho projection
    //return (w - p[3][3]) / p[2][3];
}

float coneTraceOcclusion(in ConeTraceSetup setup, const highp sampler2D depthTexture) {
    // skip fragments that are back-facing trace direction
    // (avoid overshadowing of translucent surfaces)
    float NoL = dot(setup.vsNormal, setup.vsConeDirection);
    if (NoL < 0.0) {
        return 0.0;
    }

    // start position of cone trace
    highp vec2 ssStartPos = setup.ssStartPos;
    highp vec3 vsStartPos = setup.vsStartPos;
    highp float ssStartPosW = getWFromProjectionMatrix(setup.screenFromViewMatrix, vsStartPos);
    highp float ssStartPosWInv = 1.0 / ssStartPosW;

    // end position of cone trace
    highp vec3 vsEndPos = setup.vsConeDirection * setup.shadowDistance + vsStartPos;
    highp float ssEndPosW = getWFromProjectionMatrix(setup.screenFromViewMatrix, vsEndPos);
    highp float ssEndPosWInv = 1.0 / ssEndPosW;
    highp vec2 ssEndPos = (setup.screenFromViewMatrix * vec4(vsEndPos, 1.0)).xy * ssEndPosWInv;

    // cone trace direction in screen-space
    float ssConeLength = length(ssEndPos - ssStartPos);     // do the math in highp
    highp vec2 ssConeVector = ssEndPos - ssStartPos;

    // direction perpendicular to cone trace direction
    vec2 perpConeDir = normalize(vec2(ssConeVector.y, -ssConeVector.x));
    float vsEndRadius = setup.coneAngleTangeant * setup.shadowDistance;

    // normalized step
    highp float dt = 1.0 / float(setup.sampleCount);

    // normalized (0 to 1) screen-space postion on the ray
    highp float t = dt * setup.jitterOffset.y;

    // calculate depth bias
    float vsDepthBias = saturate(1.0 - NoL) * setup.slopeScaledDepthBias + setup.depthBias;

    float occlusion = 0.0;
    for (uint i = 0u; i < setup.sampleCount; i++, t += dt) {
        float ssTracedDistance = ssConeLength * t;
        float ssSliceRadius = setup.jitterOffset.x * (setup.coneAngleTangeant * ssTracedDistance);
        highp vec2 ssSamplePos = perpConeDir * ssSliceRadius + ssConeVector * t + ssStartPos;

        float level = clamp(floor(log2(ssSliceRadius)) - kSSCTLog2LodRate, 0.0, float(setup.maxLevel));
        float vsSampleDepthLinear = -sampleDepthLinear(depthTexture, ssSamplePos * setup.resolution.zw, 0.0);

        // calculate depth range of cone slice
        float vsSliceRadius = vsEndRadius * t;

        // calculate depth of cone center
        float vsConeAxisDepth = -getViewSpaceZFromW(setup.screenFromViewMatrix, 1.0 / mix(ssStartPosWInv, ssEndPosWInv, t));
        float vsJitteredSampleRadius = vsSliceRadius * setup.jitterOffset.x;
        float vsSliceHalfRange = sqrt(vsSliceRadius * vsSliceRadius - vsJitteredSampleRadius * vsJitteredSampleRadius);
        float vsSampleDepthMax = vsConeAxisDepth + vsSliceHalfRange;

        // calculate overlap of depth buffer height-field with trace cone
        float vsDepthDifference = vsSampleDepthMax - vsSampleDepthLinear;
        float overlap = saturate((vsDepthDifference - vsDepthBias) / (vsSliceHalfRange * 2.0));

        // attenuate by distance to avoid false occlusion
        float attenuation = saturate(1.0 - (vsDepthDifference * setup.contactDistanceMaxInv));
        occlusion = max(occlusion, overlap * attenuation);
        if (occlusion >= 1.0) {  // note: this can't get > 1.0 by construction
            // fully occluded, early exit
            break;
        }
    }
    return occlusion * setup.intensity;
}

float ssctDominantLightShadowing(highp vec2 uv, highp vec3 origin, vec3 normal,
        const highp sampler2D depthTexture, const highp vec2 fragCoord,
        vec2 rayCount, ConeTraceSetup cone) {

    float occlusion = 0.0;
    for (float i = 1.0; i <= rayCount.x; i += 1.0) {
        cone.jitterOffset.x = interleavedGradientNoise(fragCoord * i) * 2.0 - 1.0;      // direction
        cone.jitterOffset.y = interleavedGradientNoise(fragCoord * i * vec2(3, 11));    // step
        occlusion += coneTraceOcclusion(cone, depthTexture);
    }
    return occlusion * rayCount.y;
}


#endif // FILAMENT_MATERIALS_SSCT

#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 16              
#endif


float dominantLightShadowing(highp vec2 uv, highp vec3 origin, vec3 normal) {
    ConeTraceSetup cone;

    cone.ssStartPos = uv * materialParams.resolution.xy;
    cone.vsStartPos = origin;
    cone.vsNormal = normal;

    cone.vsConeDirection = materialParams.ssctVsLightDirection;
    cone.shadowDistance = materialParams.ssctShadowDistance;
    cone.coneAngleTangeant = materialParams.ssctConeAngleTangeant;
    cone.contactDistanceMaxInv = materialParams.ssctContactDistanceMaxInv;

    cone.screenFromViewMatrix = materialParams.screenFromViewMatrix;
    cone.projectionScale = materialParams.projectionScale;
    cone.resolution = materialParams.resolution;
    cone.maxLevel = float(materialParams.maxLevel);

    cone.intensity = materialParams.ssctIntensity;
    cone.depthBias = materialParams.ssctDepthBias.x;
    cone.slopeScaledDepthBias = materialParams.ssctDepthBias.y;
    cone.sampleCount = materialParams.ssctSampleCount;

    return ssctDominantLightShadowing(uv, origin, normal,
            materialParams_depth, getFragCoord(materialParams.resolution.xy),
            materialParams.ssctRayCount, cone);
}

#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 132          
#endif

    #if defined(GL_GOOGLE_cpp_style_line_directive)
#line 0                       
#endif
/*
 * Copyright (C) 2021 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef FILAMENT_MATERIALS_GEOMETRY
#define FILAMENT_MATERIALS_GEOMETRY

#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 0                
#endif
/*
 * Copyright (C) 2021 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef FILAMENT_MATERIALS_DEPTH_UTILS
#define FILAMENT_MATERIALS_DEPTH_UTILS

highp float linearizeDepth(highp float depth) {
    // Our far plane is at infinity, which causes a division by zero below, which in turn
    // causes some issues on some GPU. We workaround it by replacing "infinity" by the closest
    // value representable in  a 24 bit depth buffer.
    const highp float preventDiv0 = 1.0 / 16777216.0;
    mat4 p = getViewFromClipMatrix();
    // this works with perspective and ortho projections, for a perspective projection
    // this resolves to -near/depth, for an ortho projection this resolves to depth*(far - near) - far
    return (depth * p[2].z + p[3].z) / max(depth * p[2].w + p[3].w, preventDiv0);
}

highp float sampleDepth(const highp sampler2D depthTexture, const highp vec2 uv, float lod) {
    return textureLod(depthTexture, uvToRenderTargetUV(uv), lod).r;
}

highp float sampleDepthLinear(const highp sampler2D depthTexture,
        const highp vec2 uv, float lod) {
    return linearizeDepth(sampleDepth(depthTexture, uv, lod));
}

#endif // #define FILAMENT_MATERIALS_DEPTH_UTILS


#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 19                       
#endif


// uv             : normalized coordinates
// linearDepth    : linear depth at uv
// positionParams : invProjection[0][0] * 2, invProjection[1][1] * 2
//
highp vec3 computeViewSpacePositionFromDepth(highp vec2 uv, highp float linearDepth,
        highp vec2 positionParams) {
    return vec3((0.5 - uv) * positionParams * linearDepth, linearDepth);
}

highp vec3 faceNormal(highp vec3 dpdx, highp vec3 dpdy) {
    return normalize(cross(dpdx, dpdy));
}

// Compute normals using derivatives, which essentially results in half-resolution normals
// this creates arifacts around geometry edges.
// Note: when using the spirv optimizer, this results in much slower execution time because
//       this whole expression is inlined in the AO loop below.
highp vec3 computeViewSpaceNormalLowQ(const highp vec3 position) {
    return faceNormal(dFdx(position), dFdy(position));
}

// Compute normals directly from the depth texture, resulting in full resolution normals
// Note: This is actually as cheap as using derivatives because the texture fetches
//       are essentially equivalent to textureGather (which we don't have on ES3.0),
//       and this is executed just once.
//
// depthTexture   : the depth texture in reversed-Z
// uv             : normalized coordinates
// position       : view space position at uv
// texel          : 1/depth_width, 1/depth_height
// positionParams : invProjection[0][0] * 2, invProjection[1][1] * 2
//
highp vec3 computeViewSpaceNormalMediumQ(
        const highp sampler2D depthTexture, const highp vec2 uv,
        const highp vec3 position,
        highp vec2 texel, highp vec2 positionParams) {

    precision highp float;

    highp vec2 uvdx = uv + vec2(texel.x, 0.0);
    highp vec2 uvdy = uv + vec2(0.0, texel.y);
    vec3 px = computeViewSpacePositionFromDepth(uvdx,
            sampleDepthLinear(depthTexture, uvdx, 0.0), positionParams);
    vec3 py = computeViewSpacePositionFromDepth(uvdy,
            sampleDepthLinear(depthTexture, uvdy, 0.0), positionParams);
    vec3 dpdx = px - position;
    vec3 dpdy = py - position;
    return faceNormal(dpdx, dpdy);
}

// Accurate view-space normal reconstruction
// Based on Yuwen Wu "Accurate Normal Reconstruction"
// (https://atyuwen.github.io/posts/normal-reconstruction)
//
// depthTexture   : the depth texture in reversed-Z
// uv             : normalized coordinates
// depth          : linear depth at uv
// position       : view space position at uv
// texel          : 1/depth_width, 1/depth_height
// positionParams : invProjection[0][0] * 2, invProjection[1][1] * 2
//
highp vec3 computeViewSpaceNormalHighQ(
        const highp sampler2D depthTexture, const highp vec2 uv,
        const highp float depth, const highp vec3 position,
        highp vec2 texel, highp vec2 positionParams) {

    precision highp float;

    vec3 pos_c = position;
    highp vec2 dx = vec2(texel.x, 0.0);
    highp vec2 dy = vec2(0.0, texel.y);

    vec4 H;
    H.x = sampleDepth(depthTexture, uv - dx, 0.0);
    H.y = sampleDepth(depthTexture, uv + dx, 0.0);
    H.z = sampleDepth(depthTexture, uv - dx * 2.0, 0.0);
    H.w = sampleDepth(depthTexture, uv + dx * 2.0, 0.0);
    vec2 he = abs((2.0 * H.xy - H.zw) - depth);
    vec3 pos_l = computeViewSpacePositionFromDepth(uv - dx,
            linearizeDepth(H.x), positionParams);
    vec3 pos_r = computeViewSpacePositionFromDepth(uv + dx,
            linearizeDepth(H.y), positionParams);
    vec3 dpdx = (he.x < he.y) ? (pos_c - pos_l) : (pos_r - pos_c);

    vec4 V;
    V.x = sampleDepth(depthTexture, uv - dy, 0.0);
    V.y = sampleDepth(depthTexture, uv + dy, 0.0);
    V.z = sampleDepth(depthTexture, uv - dy * 2.0, 0.0);
    V.w = sampleDepth(depthTexture, uv + dy * 2.0, 0.0);
    vec2 ve = abs((2.0 * V.xy - V.zw) - depth);
    vec3 pos_d = computeViewSpacePositionFromDepth(uv - dy,
            linearizeDepth(V.x), positionParams);
    vec3 pos_u = computeViewSpacePositionFromDepth(uv + dy,
            linearizeDepth(V.y), positionParams);
    vec3 dpdy = (ve.x < ve.y) ? (pos_c - pos_d) : (pos_u - pos_c);
    return faceNormal(dpdx, dpdy);
}

// depthTexture   : the depth texture in reversed-Z
// uv             : normalized coordinates
// depth          : linear depth at uv
// position       : view space position at uv
// texel          : 1/depth_width, 1/depth_height
// positionParams : invProjection[0][0] * 2, invProjection[1][1] * 2
//
highp vec3 computeViewSpaceNormal(
        const highp sampler2D depthTexture, const highp vec2 uv,
        const highp float depth, const highp vec3 position,
        highp vec2 texel, highp vec2 positionParams) {
    // todo: maybe make this a quality parameter
#if FILAMENT_QUALITY == FILAMENT_QUALITY_HIGH
    vec3 normal = computeViewSpaceNormalHighQ(depthTexture, uv, depth, position,
            texel, positionParams);
#else
    vec3 normal = computeViewSpaceNormalMediumQ(depthTexture, uv, position,
            texel, positionParams);
#endif
    return normal;
}

#endif // FILAMENT_MATERIALS_GEOMETRY

#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 133          
#endif

    #if defined(GL_GOOGLE_cpp_style_line_directive)
#line 0               
#endif
/*
 * Copyright (C) 2021 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef FILAMENT_MATERIALS_SSAO_UTILS
#define FILAMENT_MATERIALS_SSAO_UTILS

#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 0                         
#endif
/*
 * Copyright (C) 2021 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef FILAMENT_MATERIALS_DEPTH_UTILS
#define FILAMENT_MATERIALS_DEPTH_UTILS

highp float linearizeDepth(highp float depth) {
    // Our far plane is at infinity, which causes a division by zero below, which in turn
    // causes some issues on some GPU. We workaround it by replacing "infinity" by the closest
    // value representable in  a 24 bit depth buffer.
    const highp float preventDiv0 = 1.0 / 16777216.0;
    mat4 p = getViewFromClipMatrix();
    // this works with perspective and ortho projections, for a perspective projection
    // this resolves to -near/depth, for an ortho projection this resolves to depth*(far - near) - far
    return (depth * p[2].z + p[3].z) / max(depth * p[2].w + p[3].w, preventDiv0);
}

highp float sampleDepth(const highp sampler2D depthTexture, const highp vec2 uv, float lod) {
    return textureLod(depthTexture, uvToRenderTargetUV(uv), lod).r;
}

highp float sampleDepthLinear(const highp sampler2D depthTexture,
        const highp vec2 uv, float lod) {
    return linearizeDepth(sampleDepth(depthTexture, uv, lod));
}

#endif // #define FILAMENT_MATERIALS_DEPTH_UTILS


#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 19               
#endif


vec2 pack(highp float normalizedDepth) {
    // we need 16-bits of precision
    highp float z = clamp(normalizedDepth, 0.0, 1.0);
    highp float t = floor(256.0 * z);
    mediump float hi = t * (1.0 / 256.0);   // we only need 8-bits of precision
    mediump float lo = (256.0 * z) - t;     // we only need 8-bits of precision
    return vec2(hi, lo);
}

highp float unpack(highp vec2 depth) {
    // depth here only has 8-bits of precision, but the unpacked depth is highp
    // this is equivalent to (x8 * 256 + y8) / 65535, which gives a value between 0 and 1
    return (depth.x * (256.0 / 257.0) + depth.y * (1.0 / 257.0));
}

vec3 packBentNormal(vec3 bn) {
    return bn * 0.5 + 0.5;
}

vec3 unpackBentNormal(vec3 bn) {
    return bn * 2.0 - 1.0;
}


#endif // FILAMENT_MATERIALS_SSAO_UTILS


#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 134          
#endif


    void dummy(){}

    void postProcess(inout PostProcessInputs postProcess) {
        highp vec2 uv = variable_vertex.xy; // interpolated to pixel center

        highp float depth = sampleDepth(materialParams_depth, uv, 0.0);
        highp float z = linearizeDepth(depth);
        highp vec3 origin = computeViewSpacePositionFromDepth(uv, z, materialParams.positionParams);

        vec3 normal = computeViewSpaceNormal(materialParams_depth, uv, depth, origin,
                materialParams.resolution.zw,
                materialParams.positionParams);

        float occlusion = 0.0;
        vec3 bentNormal; // will be discarded

        if (materialParams.intensity > 0.0) {
            scalableAmbientObscurance(occlusion, bentNormal, uv, origin, normal);
        }

        if (materialParams.ssctIntensity > 0.0) {
            occlusion = max(occlusion, dominantLightShadowing(uv, origin, normal));
        }

        // occlusion to visibility
        float aoVisibility = pow(saturate(1.0 - occlusion), materialParams.power);

#if defined(TARGET_MOBILE)
        // this line is needed to workaround what seems to be a bug on qualcomm hardware
        aoVisibility += gl_FragCoord.x * MEDIUMP_FLT_MIN;
#endif

        postProcess.color.rgb = vec3(aoVisibility, pack(origin.z * materialParams.invFarPlane));
    }
#line 1816
#if defined(GL_GOOGLE_cpp_style_line_directive)
#line 0                  
#endif
void main() {
    PostProcessInputs inputs;

    // Invoke user code
    postProcess(inputs);

#if defined(FRAG_OUTPUT0)
    FRAG_OUTPUT_AT0 FRAG_OUTPUT_SWIZZLE0 = inputs.FRAG_OUTPUT0;
#endif
#if defined(FRAG_OUTPUT1)
    FRAG_OUTPUT_AT1 FRAG_OUTPUT_SWIZZLE1 = inputs.FRAG_OUTPUT1;
#endif
#if defined(FRAG_OUTPUT2)
    FRAG_OUTPUT_AT2 FRAG_OUTPUT_SWIZZLE2 = inputs.FRAG_OUTPUT2;
#endif
#if defined(FRAG_OUTPUT3)
    FRAG_OUTPUT_AT3 FRAG_OUTPUT_SWIZZLE3 = inputs.FRAG_OUTPUT3;
#endif
#if defined(FRAG_OUTPUT4)
    FRAG_OUTPUT_AT4 FRAG_OUTPUT_SWIZZLE4 = inputs.FRAG_OUTPUT4;
#endif
#if defined(FRAG_OUTPUT5)
    FRAG_OUTPUT_AT5 FRAG_OUTPUT_SWIZZLE5 = inputs.FRAG_OUTPUT5;
#endif
#if defined(FRAG_OUTPUT6)
    FRAG_OUTPUT_AT6 FRAG_OUTPUT_SWIZZLE6 = inputs.FRAG_OUTPUT6;
#endif
#if defined(FRAG_OUTPUT7)
    FRAG_OUTPUT_AT7 FRAG_OUTPUT_SWIZZLE7 = inputs.FRAG_OUTPUT7;
#endif
#if defined(FRAG_OUTPUT_DEPTH)
    gl_FragDepth = inputs.depth;
#endif
}

